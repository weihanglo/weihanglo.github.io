<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="本文譯自 Tokio internals: Understanding Rust&rsquo;s asynchronous I/O framework from the bottom up。
Thanks David Simmons for this awesome article!
 Tokio 是 Rust 的開發框架，用於開發非同步 I/O 程式（asynchronous I/O，一種事件驅動的作法，可實現比傳統同步 I/O 更好的延伸性、效能與資源利用）。可惜的是，Tokio 過於精密的抽象設計，招致難以學習的惡名。即使我讀完教程後，依然不認為自己充分內化這些抽象層，以便推斷實際發生的事情。
從前的非同步 I/O 相關開發經驗甚至阻礙我學習 Tokio。我習慣使用作業系統提供的 selection 工具（例如 Linux epoll）當作起點，再轉移至 dispatch、state machine 等等。倘若直接從 Tokio 抽象層出發，卻沒有清楚了解 epoll_wait() 在何處及如何發生，我會覺得難以連結每個概念。Tokio 與 future-driven 的方法就好像一個黑盒子。
我決定不繼續由上而下的方法學習 Tokio，反其道而行，而是透過閱讀原始碼，確切理解具體實作是如何驅動從 epoll 事件到 Future::poll() 消耗 I/O 的整個過程。我不會深入高層次的 Tokio 與 futures 使用細節，現有的教程 有更完整詳細的內容。除了簡短的小結，我也不會探討一般性的非同步 I/O 問題，畢竟這些問題都可寫個獨立的主題了。我的目標是有信心讓 futures 與 Tokio 以我所認知的方式執行。
首先，有些重要的聲明。請注意，Tokio 正快速開發中，這裡所見所聞可能不久就會過時。這個研究中我用了 tokio-core 0."><meta name=theme-color content="#ffcd00"><meta property="og:title" content="【譯】Tokio 內部機制：從頭理解 Rust 非同步 I/O 框架 • Weihang Lo"><meta property="og:description" content="本文譯自 Tokio internals: Understanding Rust&rsquo;s asynchronous I/O framework from the bottom up。
Thanks David Simmons for this awesome article!
 Tokio 是 Rust 的開發框架，用於開發非同步 I/O 程式（asynchronous I/O，一種事件驅動的作法，可實現比傳統同步 I/O 更好的延伸性、效能與資源利用）。可惜的是，Tokio 過於精密的抽象設計，招致難以學習的惡名。即使我讀完教程後，依然不認為自己充分內化這些抽象層，以便推斷實際發生的事情。
從前的非同步 I/O 相關開發經驗甚至阻礙我學習 Tokio。我習慣使用作業系統提供的 selection 工具（例如 Linux epoll）當作起點，再轉移至 dispatch、state machine 等等。倘若直接從 Tokio 抽象層出發，卻沒有清楚了解 epoll_wait() 在何處及如何發生，我會覺得難以連結每個概念。Tokio 與 future-driven 的方法就好像一個黑盒子。
我決定不繼續由上而下的方法學習 Tokio，反其道而行，而是透過閱讀原始碼，確切理解具體實作是如何驅動從 epoll 事件到 Future::poll() 消耗 I/O 的整個過程。我不會深入高層次的 Tokio 與 futures 使用細節，現有的教程 有更完整詳細的內容。除了簡短的小結，我也不會探討一般性的非同步 I/O 問題，畢竟這些問題都可寫個獨立的主題了。我的目標是有信心讓 futures 與 Tokio 以我所認知的方式執行。
首先，有些重要的聲明。請注意，Tokio 正快速開發中，這裡所見所聞可能不久就會過時。這個研究中我用了 tokio-core 0."><meta property="og:url" content="https://weihanglo.tw/posts/2018/tokio-internals/"><meta property="og:site_name" content="Weihang Lo"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:tag" content="Rust"><meta property="article:tag" content="Tokio"><meta property="article:tag" content="Asynchronous"><meta property="article:tag" content="Translation"><meta property="article:published_time" content="2018-01-05T08:44:43+08:00"><meta property="article:modified_time" content="2018-01-05T08:44:43+08:00"><meta name=twitter:card content="summary"><meta name=generator content="Hugo 0.74.3"><title>【譯】Tokio 內部機制：從頭理解 Rust 非同步 I/O 框架 • Weihang Lo</title><link rel=canonical href=https://weihanglo.tw/posts/2018/tokio-internals/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/assets/css/main.ab98e12b.css><link rel=stylesheet href=/css/custom.css><style>:root{--color-accent:#ffcd00}</style></head><body class="page type-posts"><div class=site><a class=screen-reader-text href=#content>Skip to Content</a><div class=main><nav id=main-menu class="menu main-menu" aria-label="Main Menu"><div class=container><ul><li class=item><a href=/>Home</a></li><li class=item><a href=/posts/>Posts</a></li><li class=item><a href=/tags/>Tags</a></li><li class=item><a href=/about/>About</a></li></ul></div></nav><div class=header-widgets><div class=container></div></div><header id=header class="header site-header"><div class="container sep-after"><div class=header-info><p class="site-title title">Weihang Lo</p><p class="desc site-desc"></p></div></div></header><main id=content><article lang=en class=entry><header class="header entry-header"><div class="container sep-after"><div class=header-info><h1 class=title>【譯】Tokio 內部機制：從頭理解 Rust 非同步 I/O 框架</h1></div><div class=entry-meta><span class=posted-on><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg><span class=screen-reader-text>Posted on</span>
<time class=entry-date datetime=2018-01-05T08:44:43+08:00>2018, Jan 05</time></span>
<span class=reading-time><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 15 15"/></svg>8 mins read</span></div></div></header><div class="container entry-content"><blockquote><p>本文譯自 <a href=https://cafbit.com/post/tokio_internals/>Tokio internals: Understanding Rust&rsquo;s asynchronous I/O framework from the bottom up</a>。<br>Thanks <a href=https://www.davidsimmons.com/>David Simmons</a> for this awesome article!</p></blockquote><p><a href=https://tokio.rs/>Tokio</a> 是 Rust 的開發框架，用於開發非同步 I/O 程式（asynchronous I/O，一種事件驅動的作法，可實現比傳統同步 I/O 更好的延伸性、效能與資源利用）。可惜的是，Tokio 過於精密的抽象設計，招致難以學習的惡名。即使我讀完教程後，依然不認為自己充分內化這些抽象層，以便推斷實際發生的事情。</p><p>從前的非同步 I/O 相關開發經驗甚至阻礙我學習 Tokio。我習慣使用作業系統提供的 selection 工具（例如 Linux epoll）當作起點，再轉移至 dispatch、state machine 等等。倘若直接從 Tokio 抽象層出發，卻沒有清楚了解 <code>epoll_wait()</code> 在何處及如何發生，我會覺得難以連結每個概念。Tokio 與 future-driven 的方法就好像一個黑盒子。</p><p>我決定不繼續由上而下的方法學習 Tokio，反其道而行，而是透過閱讀原始碼，確切理解具體實作是如何驅動從 epoll 事件到 <code>Future::poll()</code> 消耗 I/O 的整個過程。我不會深入高層次的 Tokio 與 futures 使用細節，<a href=https://tokio.rs/docs/getting-started/tokio/>現有的教程</a> 有更完整詳細的內容。除了簡短的小結，我也不會探討一般性的非同步 I/O 問題，畢竟這些問題都可寫個獨立的主題了。我的目標是有信心讓 futures 與 Tokio 以我所認知的方式執行。</p><p>首先，有些重要的聲明。請注意，Tokio 正快速開發中，這裡所見所聞可能不久就會過時。這個研究中我用了 <code>tokio-core 0.1.10</code>、<code>futures- 0.1.17</code> 與 <code>mio 0.6.10</code>。由於我想從最底層理解 Tokio，我並不會考慮更高層次的套件如 <code>tokio-proto</code> 與 <code>tokio-service</code>。tokio-core 的事件系統本身有許多細節，為了精簡，我會盡量避開這些細項。我在 Linux 作業系統上研究 Tokio，而有些討論細節與作業系統相依，如 epoll。最後，這裡所有東西都是我這個 Tokio 新手的詮釋，可能會有錯誤或誤導。</p><h2 id=asynchronous-io-in-a-nutshell>Asynchronous I/O in a nutshell</h2><p>同步 I/O 程式會執行阻塞性的 I/O 操作，直到操作完成。例如讀取會阻塞至資料抵達，寫入會阻塞線程直到欲傳遞的 bytes 送達 kernel。這些操作非常適合依序執行的傳統命令式程式設計。舉例來說，一個 HTTP 伺服器替每個新連線產生一個新線程，這個線程會讀取資料並阻塞線程直到接收完整的 request，之後處理請求，再來阻塞線程至資料完全寫入 response。這是個方法非常直觀，缺點是會阻塞線程，因此每個連線的線程要各自獨立，每個線程也需有自己的 stack。然而，線程開銷阻礙了伺服器處理大量連線的可延伸性（參閱 <a href=https://wikipedia.org/wiki/C10k_problem>C10k problem</a>)，對低階系統來說也不易負荷。</p><p>如果 HTTP server 使用非同步 I/O 開發，換句話說，在同一個線程上處理所有 I/O 操作。如此一來，所有活躍的連線以及 socket 監聽都會配置為非阻塞狀態（non-blocking），並在 event loop 中監控讀取與寫入是否就緒，進而在事件發生時分派給對應的處理程式（handler）。而每個連線都需維護自身的狀態與 buffer，如果一個處理程式一次僅能從 200 bytes 的 request 中讀取 100 個位元組（bytes），它就不能等待剩下的 bytes 而造成線程阻塞，處理程式必須將部分資料儲存在 buffer 中，設定當前的狀態為「讀取請求中」，並返回給 event loop。待到下一次連線調用的相同的處理程式，它才可讀取剩餘的 bytes 並將狀態轉為「寫入回應中」。如此的資源管理系統將會非常迅速，但同時也產生更複雜的 state machine 與容易出錯的毛病。</p><p>理想中的非同步 I/O 框架應該要提供能寫出近似於同步 I/O 的程式，但底層是 event loop 與 state machine。這對每個語言來說都很不容易，不過 Tokio 的實現已接近了。</p><h2 id=the-tokio-stack>The Tokio stack</h2><p><img src=https://cafbit.com/resource/tokio/tokio-stack.svg alt></p><p>Tokio 的技術棧由下列幾個部分組成：</p><ol><li><strong>The system selector</strong>。每個作業系統皆提供接收 I/O 事件的工具，如 epoll（linux）、<code>kqueue()</code>（FreeBSD/macOS），與 IOCP（Windows）。</li><li><strong>Mio - Metal I/O</strong>。<a href=https://docs.rs/mio/0.6.10/mio/>Mio</a> 是一個 Rust crate，提供低階通用的 I/O API，內部處理特定作業系統的 selector 實作細節，所以你不需再處理這件事。</li><li><strong>Futures</strong>。<a href=https://docs.rs/futures/0.1.17/futures/>Futures</a> 以強大的抽象來表示尚未發生的事物。這些 future 以許多好用的方式組合成另一新的複合 future 來代表一系列複雜的事件。這個抽象層足以通用於許多 I/O 之外的事件，但在 Tokio 中
，我們專注在利用 futures 開發非同步 I/O state machines。</li><li><strong>Tokio</strong>。<a href=https://docs.rs/tokio-core/0.1.10/tokio_core/>tokio-core</a> 提供一個中心的 event loop，這個 event loop 整合 Mio 回應 I/O 事件，並驅動 futures 完成（completion）。</li><li><strong>Your program</strong>。一個採用 Tokio 框架的程式，會以 futures 操作非同步 I/O，並將這些 futures 傳遞給 Tokio 的 event loop 來執行。</li></ol><h2 id=mio-metal-io>Mio: Metal I/O</h2><p>Mio 旨在提供一系列低階的 I/O API，允許調用端接收事件，如 socket 讀寫就緒狀態（readiness state）改變等。重點如下：</p><ol><li><p><strong>Poll 與 Evented</strong>。Mio 提供 <a href=https://docs.rs/mio/0.6.10/mio/event/trait.Evented.html><code>Evented</code></a> trait 來表示任何可當作事件來源的事物。在你的 event loop 中，你會利用 <a href=https://docs.rs/mio/0.6.10/mio/struct.Poll.html><code>mio::Poll</code></a> 物件註冊一定數量的 <code>Evented</code>，再調用 <a href=https://docs.rs/mio/0.6.10/mio/struct.Poll.html#method.poll><code>mio::Poll::poll</code></a> 來阻塞 loop，直到一至多個 <code>Evented</code> 產生事件（或超時）。</p></li><li><p><strong>System selector</strong>。Mio 提供可跨平台的 system selector 訪問，所以 Linux epoll、Windows IOCP、FreeBSD/macOS <code>kqueue()</code>，甚至許多有潛力的平台都可調用相同的 API。不同平台使用 Mio API 的開銷不盡相同。由於 Mio 是提供基於 readiness（就緒狀態）的 API，與 Linux epoll 相似，不少 API 在 Linux 上都可以一對一映射。（例如：<code>mio::Events</code> 實質上是一個 <code>struct epoll_event</code> 陣列。）對比之下，Windows IOCP 是基於完成（completion-based）而非基於 readiness 的 API，所以兩者間會需要較多橋接。Mio 同時提供自身版本的 <code>std::net</code> struct 如 <code>TcpListener</code>、<code>TcpStream</code> 與 <code>UdpSocket</code>。這些 API 封裝 <code>std::net</code> 版本的 API，預設為非阻塞且提供 <code>Evented</code> 實作讓其將 socket 加入 system selector。</p></li><li><p><strong>Non-system events</strong>。Mio 除了提供從 I/O 所得的 readiness 狀態來源，也可以用來指示從 user-space 來的 readiness 事件（非系統事件）。舉例來說，當一個工作線程（worker thread）完成一單位的工作，它就可以向 event loop 發出完成信號。你的程式調用 <a href=https://docs.rs/mio/0.6.10/mio/struct.Registration.html#method.new2><code>Registration::new2()</code></a> 以取得一個 <code>(Registration, SetReadiness)</code> 元組。<code>Registration</code> 是一個實作 <code>Evented</code> 且藉由 Mio 註冊在 event loop 的物件；而需要指示當前 readiness 狀態時，則會調用 <a href=https://docs.rs/mio/0.6.10/mio/struct.SetReadiness.html#method.set_readiness><code>SetReadiness::set_readiness</code></a>。在 Linux 上，非系統事件通知以 pipe 實作，當調用 <code>SetReadiness::set_readiness()</code> 時，會將 <code>0x01</code> 這個位元組寫入 pipe 中。而 <code>mio::Poll</code> 底層的 epoll 會配置為監控 pipe 讀取結束，所以 <code>epoll_wait()</code> 會解除阻塞，而 Mio 就可以將事件傳遞到調用端。另外，無論註冊多少非系統事件，都只會在 Poll 實例化時建立唯一一個 pipe。</p></li></ol><p>每個 <code>Evented</code> 的註冊皆與一個由調用端提供 <code>usize</code> 型別的 <a href=https://docs.rs/mio/0.6.10/mio/struct.Token.html><code>mio::Token</code></a> 綁定，這個 token 將會與事件一起返回，以指示出對應的註冊資訊。這種作法很好地映射到 Linux 的 system selector，因為 token 可以放置在 64-bit 的 <code>epoll_data</code> union 中，並保持相同的功能。</p><p>這裡提供一個 Mio 操作的實際案例，下面是我們在 Linux 上使用 Mio 監控一個 UDP socket 的情況：</p><ol><li><p><strong>建立 socket</strong>。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=color:#66d9ef>let</span> socket <span style=color:#f92672>=</span> mio::net::UdpSocket::bind(
    <span style=color:#f92672>&amp;</span>SocketAddr::new(
        std::net::IpAddr::V4(std::net::Ipv4Addr::new(<span style=color:#ae81ff>127</span>,<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>1</span>)),
        <span style=color:#ae81ff>2000</span>
    )
).unwrap();
</code></pre></div><p>建立一個 Linux UDP socket，其中封裝一個 <code>std::net::UdpSocket</code>，再封裝在 <code>mio::net::UdpSocket</code> 中。這個 socket 為非阻塞性（non-blocking）。</p></li><li><p><strong>建立 poll 實例</strong>。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=color:#66d9ef>let</span> poll <span style=color:#f92672>=</span> mio::Poll::new().unwrap();
</code></pre></div><p>在這步驟，Mio 初始化 system selector、readiness 佇列（用於非系統事件），以及併發保護。當 readiness 佇列初始化時，會建立一個 pipe，讓 readiness 從 user-space 發出信號，而這個 pipe 的檔案描述符（file descriptor）會加入 epoll 中。每個 <code>Poll</code> 物件建立時，都會賦予一個獨特、遞增的 <code>selector_id</code>。</p></li><li><p><strong>透過 poll 註冊 socket</strong>。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust>poll.register(
    <span style=color:#f92672>&amp;</span>socket,
    mio::Token(<span style=color:#ae81ff>0</span>),
    mio::Ready::readable(),
    mio::PollOpt::level()
).unwrap();
</code></pre></div><p><code>UdpSocket</code> 的 <code>Evented::register()</code> 被調用時，會將代理指向一個封裝的 <code>EventedFd</code>，這個 <code>EventedFd</code> 會將 socket 的 file descriptor 加入 poll selector 中（最終會調用 <code>epoll_ctl(fepd, EPOLL_CTL_ADD, fd, &epoll_event)</code>，而 <code>epoll_event.data</code> 設置為傳入的 token 值）。當一個 <code>UdpSocket</code> 註冊後，<code>selector_id</code> 會設置到與傳入的 <code>Poll</code> 相同，從而與 selector 產生連結。</p></li><li><p><strong>在 event loop 中呼叫 <code>poll()</code></strong>。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=color:#66d9ef>loop</span> {
    poll.poll(<span style=color:#f92672>&amp;</span><span style=color:#66d9ef>mut</span> events, None).unwrap();
    <span style=color:#66d9ef>for</span> event <span style=color:#66d9ef>in</span> <span style=color:#f92672>&amp;</span>events {
        handle_event(event);
    }
}
</code></pre></div><p>System selector（<code>epoll_wait()</code>）與 readiness 佇列將會輪詢（poll）新的事件。（<code>epoll_wait()</code> 會阻塞，但由於非系統事件是透過 pipe 出發 epoll，事件仍會即時處理。）這一系列組合的事件可供調用端處理。</p></li></ol><h2 id=futures-and-tasks>Futures and Tasks</h2><p><a href=https://wikipedia.org/wiki/Futures_and_promises>Futures</a> 是從函數式程式設計借來的技術，一個尚未完成的運算會以一個 future 代表，而這些獨立的 future 可以組合起來，開發更複雜的系統。這個概念對非同步 I/O 非常中用，因為在處理交易（transaction）的所有基礎步驟，都可以模化為合成 futures（combinded futures）。以 HTTP 伺服器為例，一個 future 讀取 request，會從接收到有效資料開始讀取到 request 結束，另一個 future 則會處理這個 request 並產生 response，再另一個 future 則會寫入 responses。</p><p>在 Rust 中，<a href=https://docs.rs/futures/0.1.17/futures/>futures crate</a> 實現了 futures。你可以透過實作 <a href=https://docs.rs/futures/0.1.17/futures/future/trait.Future.html>Future</a> trait 來定義自己的 future，這個 trait 需實現 <a href=https://docs.rs/futures/0.1.17/futures/future/trait.Future.html#tymethod.poll><code>poll()</code></a> 方法，這個方法會在需要時調用，允許 future 開始執行。<code>poll()</code> 方法會回傳一個錯誤（error），或回傳一個指示告知 future 仍在處理，或是當 future 完成時返回一個值。<code>Future</code> trait 也提供許多組合操作子（combinator）作為預設方法。</p><p>欲理解 futures，須先探討三個重要的概念：<strong>tasks</strong>、<strong>executors</strong>，以及 <strong>notifications</strong>，且需理解此三者該如何安排，才能在正確時間點調用 future 的 <code>poll()</code> 方法。每一個 future 都在一個 task 語彙環境（context）中執行。一個 task 只與一個 future 關聯，而這個 future 卻可能是一個合成的 future，驅動其他封裝的 futures。（舉例來說，多個 future 用 <code>join_all()</code> 組合操作子，串連成單一一個 future，或是兩個 future 利用 <code>and_then()</code> 組合操作子來依序執行。）</p><p>Task 與它的 futures 需要被一個 <em>executor</em> 執行。一個 executor 的責任是在正確時間點輪詢 task/future，輪詢通常會在接收到執行進度開始的通知時。而這個通知將在一個實作 <a href=https://docs.rs/futures/0.1.17/futures/executor/trait.Notify.html><code>futures::executor::Notify</code></a> trait 的物件調用 <a href=https://docs.rs/futures/0.1.17/futures/executor/trait.Notify.html><code>notify</code></a> 時發布。這裡有個例子，是由 futures crate 所提供的非常簡單的 executor，在調用 future 上的 <a href=https://docs.rs/futures/0.1.17/futures/future/trait.Future.html#method.wait><code>wait()</code></a> 被呼叫。擷自<a href=https://github.com/alexcrichton/futures-rs/blob/0.1.17/src/task_impl/std/mod.rs#L233>原始碼</a>：</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=color:#e6db74>/// Waits for the internal future to complete, blocking this thread&#39;s
</span><span style=color:#e6db74>/// execution until it does.
</span><span style=color:#e6db74>///
</span><span style=color:#e6db74>/// This function will call `poll_future` in a loop, waiting for the future
</span><span style=color:#e6db74>/// to complete. When a future cannot make progress it will use
</span><span style=color:#e6db74>/// `thread::park` to block the current thread.
</span><span style=color:#e6db74></span><span style=color:#66d9ef>pub</span> <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>wait_future</span>(<span style=color:#f92672>&amp;</span><span style=color:#66d9ef>mut</span> self) -&gt; Result<span style=color:#f92672>&lt;</span>F::Item, F::Error<span style=color:#f92672>&gt;</span> {
    ThreadNotify::with_current(<span style=color:#f92672>|</span>notify<span style=color:#f92672>|</span> {

        <span style=color:#66d9ef>loop</span> {
            <span style=color:#66d9ef>match</span> self.poll_future_notify(notify, <span style=color:#ae81ff>0</span>)<span style=color:#f92672>?</span> {
                Async::NotReady <span style=color:#f92672>=&gt;</span> notify.park(),
                Async::Ready(e) <span style=color:#f92672>=&gt;</span> <span style=color:#66d9ef>return</span> Ok(e),
            }
        }
    })
}
</code></pre></div><p>給定一個融合 task 與 future 的 <a href=https://docs.rs/futures/0.1.17/futures/executor/struct.Spawn.html><code>futures::executor::Spawn</code></a> 物件，這個 executor 在迴圈中調用 <a href=https://docs.rs/futures/0.1.17/futures/executor/struct.Spawn.html#method.poll_future_notify><code>poll_future_notify</code></a>。這個 <code>Notify</code> 會成為 task 執行語彙環境的一部分，future 也會被輪詢。如果一個 future <code>poll</code> 方法回傳 <code>Async::NotReady</code>，表示 future 仍等待中，必須在往後再次輪詢。<code>Notify</code> object 會從 <a href=https://docs.rs/futures/0.1.17/futures/task/fn.current.html><code>futures::task::current()</code></a> 取得一個指向 task 的 handle，且在 future 有些進展時調用 <a href=https://docs.rs/futures/0.1.17/futures/task/struct.Task.html#method.notify><code>notify()</code></a> 方法。（當一個 future 被輪詢時，與該 future 相關的 task 訊息將會儲存到 thread-local 中，thread-local 可以透過 <code>current()</code> 存取取得。）上例中，如果輪詢回傳 <code>Async::NotReady</code>，executor 會阻塞至接收到通知。也許 future 在其他線程運算，在完成時調用 <code>notify()</code>；或是 <code>poll()</code> 方法在返回 <code>Asynx::NotReady</code> 之前，自身直接調用了 <code>notify()</code>（後者並不常見，因為理論上一個 <code>poll()</code> 在返回之前應該持續取得進展）。</p><p>Tokio 的 event loop 行為上比簡單整合「 Mio 事件驅動 future 完成」來得精細。舉例來說，一個 Mio event 表示一個 socket 的 readiness（就緒狀態），最後會產生一個通知，足以告知相對應的 future 需要輪詢。</p><p>處理 future 時，Task 是最基礎的執行單元，且基本上就是<a href=https://en.wikipedia.org/wiki/Green_threads>綠色線程</a>，提供<a href=https://en.wikipedia.org/wiki/Cooperative_multitasking>協調式多工</a>，允許在同一個系統線程有多個執行語彙環境。當一個 task 無法有所進展，會讓處理器先處理其他可執行的 task。我們必須理解的是，「通知」會發生在 task 層級而非 future 層級。當一個 task 被通知時，它會輪詢它連結的最高層級的 future，這會導致任何或是全部的 child future 同樣被輪詢。例如，如果一個 task 最高層級的 future 是一個以 <a href=https://docs.rs/futures/0.1.17/futures/future/fn.join_all.html><code>join_all</code></a> 組合的十個 future，而其中一個 future 安排要通知此一 task，則無論需不需要，全部十個 future 皆須接受輪詢。</p><h2 id=tokios-interface-with-mio>Tokio&rsquo;s interface with Mio</h2><p>Tokio 利用上述的 Mio 「非系統事件」，將 task 通知轉換為 Mio 的事件。在取得一個 Mio 的 (<code>Registration</code>、<code>SetReadiness</code>）元組後，Tokio 會將 <code>Registration</code>（一個 <code>Evented</code>）註冊至 Mio 的 poll （event loop）中，再將 <code>SetReadiness</code> 封裝在實作了 <code>Notify</code> trait 的 <code>MySetReadiness</code> 中。<a href=https://github.com/tokio-rs/tokio-core/blob/0.1.10/src/reactor/mod.rs#L791>原始碼</a>如下：</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=color:#66d9ef>struct</span> <span style=color:#a6e22e>MySetReadiness</span>(mio::SetReadiness);

<span style=color:#66d9ef>impl</span> Notify <span style=color:#66d9ef>for</span> MySetReadiness {
    <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>notify</span>(<span style=color:#f92672>&amp;</span>self, _id: <span style=color:#66d9ef>usize</span>) {
        self.<span style=color:#ae81ff>0.</span>set_readiness(mio::Ready::readable())
              .expect(<span style=color:#e6db74>&#34;failed to set readiness&#34;</span>);
    }
}
</code></pre></div><p>在這個作法中，task 的通知將轉換為 Mio 事件，且可以透過 Tokio 的事件處理與分派機制與其他 Mio 事件作伙處理。</p><p>如同 Mio 封裝 <code>std::net</code> 內的 <code>UdpSocket</code>、<code>TcpListener</code>，以及 <code>TcpStream</code> 來客製化需求，Tokio 也利用了組合（composition）與裝飾（decoration）建立這些型別的 Tokio 版。舉例來說，Tokio 的 <code>UdpSocket</code> 架構大致如下：</p><p><img src=https://cafbit.com/resource/tokio/udpsocket.svg alt></p><p>Tokio 版本的 I/O 來源型別的建構子都需要傳入 event loop 的 handle（<a href=https://docs.rs/tokio-core/0.1.10/tokio_core/reactor/struct.Handle.html><code>tokio_core::reactor::Handle</code></a>）。當實例化時，這些型別會將它們的 socket 註冊至 Mio poll 的 event loop 上，以利接收 edge-triggred（譯注：一種 epoll event 的觸發模式）的事件及其新賦予的偶數數字 token（以下會解釋）。當底層的 I/O 操作回傳 <code>WouldBlock</code> 時，這些型別可以很方便地安排當前的 task 來接收讀寫的 readiness。</p><p>Tokio 在 Mio 上註冊了許多 <code>Evented</code> 型別，儲存在特定的 token 上：</p><ul><li><p><strong>Token 0（<code>TOKEN_MESSAGES</code>）</strong>：用於 Tokio 內部的消息佇列（message queue），這個佇列提供移除 I/O 來源、接收讀寫 readiness 通知的 task 排程，設定 timeout，以及執行在 event loop 語彙環境中的任意閉包。這個 token 可以安全地從其他線程與 event loop 溝通。例如，<a href=https://docs.rs/tokio-core/0.1.10/tokio_core/reactor/struct.Remote.html#method.spawn><code>Remote::spawn()</code></a> 透過訊息系統，將 future 送達 event loop。</p><p>實作上，消息佇列是一個 <a href=https://docs.rs/futures/0.1.17/futures/sync/mpsc/index.html><code>futures::sync::mpsc</code></a> stream。身為一個 <a href=https://docs.rs/futures/0.1.17/futures/stream/trait.Stream.html><code>futures::stream::Stream</code></a>（與 future 類似，但是產生一序列的值而非單一值），消息佇列使用上述 <code>MySetReadiness</code> 方案來處理，而 <code>Registration</code> 則是以 <code>TOKEN_MESSAGES</code> 這個 token 註冊。當接收到 <code>TOKEN_MESSAGES</code> 事件時，該事件會分派到 <code>consume_queue()</code> 方法進一步處理。（原始碼：<a href=https://github.com/tokio-rs/tokio-core/blob/0.1.10/src/reactor/mod.rs#L133><code>enum Message</code></a>、<a href=https://github.com/tokio-rs/tokio-core/blob/0.1.10/src/reactor/mod.rs#L403><code>consume_queue()</code></a>）</p></li><li><p><strong>Token 1（<code>TOKEN_FUTURE</code>）</strong>：用於通知 Tokio 需要輪詢 main task。這個 token 會在與 main task 相關聯的通知上（也就是傳入 <code>Core::run()</code> 的 future 或它的子 future，而非透過 <code>spawn()</code> 在不同 task 中執行的 future）。這個事件同樣用了 <code>MySetReadiness</code> 方案將 future 轉譯成 Mio 的事件。在一個 future 被 main task 執行前，會先回傳 <code>Async::NotReady</code>，並以其所選的方式在稍後發布通知。當接收了 <code>TOKEN_FUTURE</code> 事件，Tokio event loop 就會再次輪詢 main task。</p></li><li><p><strong>大於 1 的偶數 token（<code>TOKEN_START + key * 2</code>）</strong>：用來指示 I/O 來源的 readiness 改變。Token 中的 key 是 <code>Slab</code> key，關聯值是 <code>Core::inner::io_dispatch Slab&lt;ScheduledIo></code>。當 Mio 的 I/O 來源型別（<code>UdpSocket</code>、<code>TcpListener</code>、<code>TcpStream</code>）實例化之初，會自動以此 token 註冊。</p></li><li><p><strong>大於 1 的奇數 token（<code>TOKEN_START + key * 2 + 1</code>）</strong>：用來指示一個 spawned task（及其關聯的 future）需要被輪詢。Token 中的 key 是 <code>Slab</code> key，關聯值是 <code>Core::inner::task_dispatch Slab&lt;ScheduledTask></code>。和 <code>TOKEN_MESSAGES</code> 與 <code>TOKEN_FUTURE</code> 事件相同，這個事件也用了 <code>MySetReadiness</code> 溝通。</p></li></ul><h2 id=tokio-event-loop>Tokio event loop</h2><p>Tokio，更精確來說是 <a href=https://docs.rs/tokio-core/0.1.10/tokio_core/reactor/struct.Core.html><code>tokio_core::reactor::Core</code></a> 提供了 event loop 來管理 futures 和 tasks，驅動 future 完成，以及與 Mio 介接的介面，讓 I/O 事件可正確通知對應的 task。使用 event loop 需透過 <a href=https://docs.rs/tokio-core/0.1.10/tokio_core/reactor/struct.Core.html#method.new><code>Core::new()</code></a> 實例化一個 <code>Core</code>，並調用 <a href=https://docs.rs/tokio-core/0.1.10/tokio_core/reactor/struct.Core.html#method.run><code>Core::run()</code></a> 傳入一個 future。這個 event loop 在返回之前，將會驅動傳入的 future 至完成。以伺服器程式來說（serve application），這個 future 很可能生命週期較長，例如使用 <code>TcpListener</code> 持續接收新傳入的連結，每個連結透過 <a href=https://docs.rs/tokio-core/0.1.10/tokio_core/reactor/struct.Handle.html#method.spawn><code>Handle.spawn()</code></a> 分別建立 task，由自身的 future 獨立處理。</p><p>以下的流程圖大略點出 Tokio event loop 的基本輪廓：</p><p><img src=https://cafbit.com/resource/tokio/tokio-event-loop.svg alt></p><h2 id=what-happens-when-data-arrives-on-a-socket>What happens when data arrives on a socket?</h2><p>想了解 Tokio，可以觀察當資料抵達 socket 時，event loop 發生的每個步驟。我很訝異地發現，這個過程最終分為兩部分，分別在 event loop 內各自的迭代中，進行各自的 epoll 交易處理。第一部分負責當 socket 讀取就緒時（例如，Mio 事件帶著比 1 大的偶數 token，或 main task 的 <code>TOKEN_FUTURE</code>），傳送通知到對該 socket 有興趣的 task；第二部分則是透過輪詢 task 與它的 future 來處理通知（例如，Mio 事件帶著比 1 大的奇數 token）。我們來了解以下情境：一個 spawned task 從 Linux 上的 <code>UdpSocket</code>，透過 Tokio event loop 讀取資料，並假設前一次輪詢結果導致 <code>recv_from()</code> 回傳一個 <code>WouldBlock</code> 錯誤。</p><p><img src=https://cafbit.com/resource/tokio/recv-sequence-1.svg alt></p><p>Tokio event loop 調用 <code>mio::Poll:poll()</code>，該方法轉而調用 <code>epoll_wait()</code>（在 Linux 上）進而阻塞到某個監測中的 file descriptor 發生了 readiness 改變的事件。當上述情形發生後，<code>epoll_wait()</code> 回傳一個 <code>epoll_event</code> structs 的陣列，用以描述發生什麼事，這些 structs 也將透過 Mio 轉譯為 <code>mio::Events</code>，並返回 Tokio。（在 Linux 上，這些轉譯應該是零成本（zero-cost），因為 <code>mio::Events</code> 就只是簡單，以一個 <code>epoll_event</code> 陣列組成的元組結構（tuple struct）。）在我們的例子，假設在陣列中只有一個事件指出 socket 已讀取就緒。由於該事件的 token 是大於 1 的偶數，Tokio 辨識其為 I/O 事件，並從 <code>Slab&lt;ScheduledIo></code> 中尋找對應的元素，以取得有哪些 task 對這個 socket 的讀寫 readiness 狀態有興趣。接下來，Tokio 會通知對讀取有興趣的 task，這些 task 透過前述的 <code>MySetReadiness</code>，調用 Mio 的 <code>set_readiness()</code>。Mio 會將這個非系統的事件詳細資訊加到 readiness 佇列中，並寫入 <code>0x01</code> 到 readiness pipe 中。</p><p><img src=https://cafbit.com/resource/tokio/recv-sequence-2.svg alt></p><p>在 Tokio event loop 往下一個迭代前進之前，它會再次輪詢 Mio，Mio 則調用 <code>epoll_wait()</code>，而 <code>epoll_wait()</code> 這次返回一個在 Mio 的 readiness pipe 上發生的讀取 readiness 事件。Mio 讀取之前寫入的 <code>0x01</code>，並從 readiness 佇列取出最前端（dequeue）的非系統事件資料，並將這個事件回傳到 Tokio。由於該事件的 token 是大於 1 的奇數 token，Tokio 辨識其為 task 通知事件，並從 <code>Slab&lt;ScheduledTask></code> 中尋找對應的元素，以取得 task 從 <code>spawn()</code> 回傳的最原始的 <code>Spawn</code> 物件。接下來，Tokio 透過 <a href=https://docs.rs/futures/0.1.17/futures/executor/struct.Spawn.html#method.poll_future_notify><code>poll_future_notify()</code></a> 輪詢這個 task 與它的 future，這個 future 可能會從 socket 讀取資料，直至得到 <code>WouldBlock</code> 錯誤。</p><p>這個二迭代的方法涉及了 pipe 讀寫，對比其他非同步 I/O event loop，可能會有一點額外開銷。如果在一個單線程的程式中，使用 <code>strace</code> 會看到一個線程用 pipe 與自己溝通，很是奇怪：</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c>pipe2([<span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>5</span>], O_NONBLOCK<span style=color:#f92672>|</span>O_CLOEXEC) <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
...
epoll_wait(<span style=color:#ae81ff>3</span>, [{EPOLLIN<span style=color:#f92672>|</span>EPOLLOUT, {u32<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>, u64<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>}}], <span style=color:#ae81ff>1024</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
write(<span style=color:#ae81ff>5</span>, <span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\1</span><span style=color:#e6db74>&#34;</span>, <span style=color:#ae81ff>1</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
epoll_wait(<span style=color:#ae81ff>3</span>, [{EPOLLIN, {u32<span style=color:#f92672>=</span><span style=color:#ae81ff>4294967295</span>, u64<span style=color:#f92672>=</span><span style=color:#ae81ff>18446744073709551615</span>}}], <span style=color:#ae81ff>1024</span>, <span style=color:#ae81ff>0</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
read(<span style=color:#ae81ff>4</span>, <span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\1</span><span style=color:#e6db74>&#34;</span>, <span style=color:#ae81ff>128</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
read(<span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>0x7ffce1140f58</span>, <span style=color:#ae81ff>128</span>) <span style=color:#f92672>=</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span> EAGAIN (Resource temporarily unavailable)
recvfrom(<span style=color:#ae81ff>12</span>, <span style=color:#e6db74>&#34;hello</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, <span style=color:#ae81ff>1024</span>, <span style=color:#ae81ff>0</span>, {sa_family<span style=color:#f92672>=</span>AF_INET, sin_port<span style=color:#f92672>=</span>htons(<span style=color:#ae81ff>43106</span>), sin_addr<span style=color:#f92672>=</span>inet_addr(<span style=color:#e6db74>&#34;127.0.0.1&#34;</span>)}, [<span style=color:#ae81ff>16</span>]) <span style=color:#f92672>=</span> <span style=color:#ae81ff>6</span>
recvfrom(<span style=color:#ae81ff>12</span>, <span style=color:#ae81ff>0x7f576621c800</span>, <span style=color:#ae81ff>1024</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0x7ffce1140070</span>, <span style=color:#ae81ff>0x7ffce114011c</span>) <span style=color:#f92672>=</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span> EAGAIN (Resource temporarily unavailable)
epoll_wait(<span style=color:#ae81ff>3</span>, [], <span style=color:#ae81ff>1024</span>, <span style=color:#ae81ff>0</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
epoll_wait(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>0x7f5765b24000</span>, <span style=color:#ae81ff>1024</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>) <span style=color:#f92672>=</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span> EINTR (Interrupted system call)
</code></pre></div><p>Mio 選用 pipe 的方案來支持通用性，以防 <code>set_readiness()</code> 可能被其他線程調用。也有可能這種作法對強制實施公平的事件調節與維持 futures 與 I/O 的間接層有所幫助。</p><h2 id=lessons-learned-combining-futures-vs-spawning-futures>Lessons learned: Combining futures vs. spawning futures</h2><p>最初探索 Tokio 時，我寫了一個小程式，負責監聽不同 UDP socket 進來的資料。這個程式建立十個讀取 socket 的 future 實例，每個都監聽不同的埠口（port）。我天真地使用 <a href=https://docs.rs/futures/0.1.17/futures/future/fn.join_all.html><code>join_all()</code></a> 將所有 future 合成為單一 future，並將之傳入 <code>Core::run()</code>，訝異的是，我發現每當一個封包送達，所有 future 都會輪詢一次。另一個驚訝的點是，<code>tokio_core::net:UdpSocket::recv_from()</code>（以及底層的 <a href=https://docs.rs/tokio-core/0.1.10/tokio_core/reactor/struct.PollEvented.html><code>PollEvented</code></a>）非常聰明，當 socket 在前一次的 Mio 輪詢中尚未標記為讀取就緒時，會避免調用作業系統 <code>rectfrom()</code>。以下的 <code>strace</code> 反映出我寫的 future <code>poll()</code> 的除錯 <code>println!()</code>，大致如下：</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c>epoll_wait(<span style=color:#ae81ff>3</span>, [{EPOLLIN<span style=color:#f92672>|</span>EPOLLOUT, {u32<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>, u64<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>}}], <span style=color:#ae81ff>1024</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
write(<span style=color:#ae81ff>5</span>, <span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\1</span><span style=color:#e6db74>&#34;</span>, <span style=color:#ae81ff>1</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
epoll_wait(<span style=color:#ae81ff>3</span>, [{EPOLLIN, {u32<span style=color:#f92672>=</span><span style=color:#ae81ff>4294967295</span>, u64<span style=color:#f92672>=</span><span style=color:#ae81ff>18446744073709551615</span>}}], <span style=color:#ae81ff>1024</span>, <span style=color:#ae81ff>0</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
read(<span style=color:#ae81ff>4</span>, <span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\1</span><span style=color:#e6db74>&#34;</span>, <span style=color:#ae81ff>128</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
read(<span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>0x7ffc183129d8</span>, <span style=color:#ae81ff>128</span>) <span style=color:#f92672>=</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span> EAGAIN (Resource temporarily unavailable)
write(<span style=color:#ae81ff>1</span>, <span style=color:#e6db74>&#34;UdpServer::poll()...</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, <span style=color:#ae81ff>21</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>21</span>
write(<span style=color:#ae81ff>1</span>, <span style=color:#e6db74>&#34;UdpServer::poll()...</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, <span style=color:#ae81ff>21</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>21</span>
write(<span style=color:#ae81ff>1</span>, <span style=color:#e6db74>&#34;UdpServer::poll()...</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, <span style=color:#ae81ff>21</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>21</span>
write(<span style=color:#ae81ff>1</span>, <span style=color:#e6db74>&#34;UdpServer::poll()...</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, <span style=color:#ae81ff>21</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>21</span>
write(<span style=color:#ae81ff>1</span>, <span style=color:#e6db74>&#34;UdpServer::poll()...</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, <span style=color:#ae81ff>21</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>21</span>
write(<span style=color:#ae81ff>1</span>, <span style=color:#e6db74>&#34;UdpServer::poll()...</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, <span style=color:#ae81ff>21</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>21</span>
write(<span style=color:#ae81ff>1</span>, <span style=color:#e6db74>&#34;UdpServer::poll()...</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, <span style=color:#ae81ff>21</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>21</span>
recvfrom(<span style=color:#ae81ff>12</span>, <span style=color:#e6db74>&#34;hello</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, <span style=color:#ae81ff>1024</span>, <span style=color:#ae81ff>0</span>, {sa_family<span style=color:#f92672>=</span>AF_INET, sin_port<span style=color:#f92672>=</span>htons(<span style=color:#ae81ff>43106</span>), sin_addr<span style=color:#f92672>=</span>inet_addr(<span style=color:#e6db74>&#34;127.0.0.1&#34;</span>)}, [<span style=color:#ae81ff>16</span>]) <span style=color:#f92672>=</span> <span style=color:#ae81ff>6</span>
getsockname(<span style=color:#ae81ff>12</span>, {sa_family<span style=color:#f92672>=</span>AF_INET, sin_port<span style=color:#f92672>=</span>htons(<span style=color:#ae81ff>2006</span>), sin_addr<span style=color:#f92672>=</span>inet_addr(<span style=color:#e6db74>&#34;127.0.0.1&#34;</span>)}, [<span style=color:#ae81ff>16</span>]) <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
write(<span style=color:#ae81ff>1</span>, <span style=color:#e6db74>&#34;recv 6 bytes from 127.0.0.1:43106 at 127.0.0.1:2006</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, <span style=color:#ae81ff>52</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>52</span>
recvfrom(<span style=color:#ae81ff>12</span>, <span style=color:#ae81ff>0x7f2a11c1c400</span>, <span style=color:#ae81ff>1024</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0x7ffc18312ba0</span>, <span style=color:#ae81ff>0x7ffc18312c4c</span>) <span style=color:#f92672>=</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span> EAGAIN (Resource temporarily unavailable)
write(<span style=color:#ae81ff>1</span>, <span style=color:#e6db74>&#34;UdpServer::poll()...</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, <span style=color:#ae81ff>21</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>21</span>
write(<span style=color:#ae81ff>1</span>, <span style=color:#e6db74>&#34;UdpServer::poll()...</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, <span style=color:#ae81ff>21</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>21</span>
write(<span style=color:#ae81ff>1</span>, <span style=color:#e6db74>&#34;UdpServer::poll()...</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, <span style=color:#ae81ff>21</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>21</span>
epoll_wait(<span style=color:#ae81ff>3</span>, [], <span style=color:#ae81ff>1024</span>, <span style=color:#ae81ff>0</span>) <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
epoll_wait(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>0x7f2a11c36000</span>, <span style=color:#ae81ff>1024</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>) <span style=color:#f92672>=</span> ...
</code></pre></div><p>有鑑於 Tokio 與 futures 的具體內部運作某個程度上對我來說有點隱晦，我想我希望背後有些魔法路由，可以只輪詢必要的 futures。當然，對 Tokio 有更深入的理解後，我的程式很明顯這樣利用 futures：</p><p><img src=https://cafbit.com/resource/tokio/futures-join.svg alt></p><p>這的確可以執行，但不夠好，尤其是當你有一拖拉庫 socket 時。由於通知在 task 層級發生，上圖中任意一個綠色方格中通知都會導致 main task 被通知。它將會輪詢 <code>FromAll</code> future 使得所有 <code>FromAll</code> 的 child future 都須接受輪詢。我真正需要的是一個簡單的 main future，使用 <code>Handle::spawn()</code> 來啟動每個封裝在各自的 task 中的 future。這種安排大致如下圖：</p><p><img src=https://cafbit.com/resource/tokio/futures-spawn.svg alt></p><p>當任何 future 安排一個通知，只有該 future 的 task 會收到通知，也只有該 future 會被輪詢（回想一下，「安排一個通知」會自動發生在 <code>tokio_core::net:UdpSocket::rect_from()</code> 從 <code>mio::net::UdpSocket::rect_from()</code> 回傳值中接收到 <code>WouldBlock</code> ）。future 組合操作子敘述表達能力強勁，可好整以暇地描述協議（protocol）的流程而不須弄髒手寫手動輪詢的狀態機。然而重要的是，你必須理解你的設計也許需要支援各自獨立，獨自且並行運作的 tasks。（譯注：而非都在 main task 上使用 <code>join_all()</code>）</p><h2 id=final-thoughts>Final thoughts</h2><p>閱讀 Tokio、Mio 以及 futures 原始碼後，大大幫助我鞏固對 Tokio 的理解，也驗證了透過理解具體實作來釐清抽象層的學習策略。這個方法在僅僅學習抽象層的狹隘使用案例時非常危險，我們必須意識到具體的示例僅是助於理解一般通例。在閱讀完原始碼之後，再次閱讀 Tokio 的教學文件，我有些馬後炮的意見：<strong>Tokio 非常合理，應該要很容易理解與上手！</strong></p><p>我仍有些問題待日後研究：</p><ul><li>Tokio 有處理 edge triggering（Linux <code>epoll</code>）的飢餓問題（starvation problem）嗎？我認為這個問題可以在 future 中，以單一一個 <code>poll()</code> 限制讀 / 寫的數量。當達到這個限制時，future 可以在顯式通知當前 task 提前返回，而非依靠 Tokio I/O 來源類型的隱式「<code>WouldBlock</code> 排程」行為。因此這使得其他 task 與 future 有機會有所進展。</li><li>Tokio 是否不依賴於將工作卸載給工作線程（worker thread）以最大化處理器核心運用，而是直接支援多線程環境下執行 event loop 嗎？</li></ul><blockquote><p><strong>2017-12-19 更新</strong>：這裡有 Reddit 對話串討論本文。Mio 的作者 Carl Lerche 在<a href=https://www.reddit.com/r/rust/comments/7klghl/tokio_internals_understanding_rusts_asynchronous/drfw5n1/>這裡</a>和<a href=https://www.reddit.com/r/rust/comments/7klghl/tokio_internals_understanding_rusts_asynchronous/drfwc1m/>這裡</a>貼了些資訊量充足的留言。除了回應上述問題，他也點出 <a href=https://docs.rs/futures/0.1.17/futures/stream/struct.FuturesUnordered.html><code>FuturesUnordered</code></a> 是一種合成 futures 的方法，只有相關的 child future 會被輪詢，以避免所有 future 像使用 <code>join_all()</code> 全部輪詢，不過這方法有些額外的記憶體配置開銷要衡量。另外，未來的 Tokio 將要遷離 <code>mio::Registration</code> 的通知方案，目的是簡化前述一些步驟。</p><p><strong>2017-12-21 更新</strong>：看起來 Hacker News 也有在<a href="https://news.ycombinator.com/item?id=15972593">討論這篇文章</a>。</p></blockquote></div><footer class=entry-footer><div class="container sep-before"><div class=tags><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2H12l8.59 8.59A2 2 0 0120.59 13.41z"/><line x1="7" y1="7" x2="7" y2="7"/></svg><span class=screen-reader-text>Tags: </span><a class=tag href=/tags/rust/>Rust</a>, <a class=tag href=/tags/tokio/>Tokio</a>, <a class=tag href=/tags/asynchronous/>Asynchronous</a>, <a class=tag href=/tags/translation/>Translation</a></div></div><div style=text-align:center;padding-top:2em><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/><img src=https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png alt=cc-by-nc-sa-4></a></div></footer></article><nav class=entry-nav><div class=container><div class="prev-entry sep-before"><a href=/posts/2017/days-with-internet-explorer-2/><span aria-hidden=true><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><line x1="20" y1="12" x2="4" y2="12"/><polyline points="10 18 4 12 10 6"/></svg>Previous</span>
<span class=screen-reader-text>Previous post: </span>與 IE 相處的日子二：淺談網頁相容性</a></div><div class="next-entry sep-before"><a href=/posts/2018/2018-interviews/><span class=screen-reader-text>Next post: </span>2018 前端工程師面試心得<span aria-hidden=true>Next<svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><line x1="4" y1="12" x2="20" y2="12"/><polyline points="14 6 20 12 14 18"/></svg></span></a></div></div></nav></main><footer id=footer class=footer><div class="container sep-before"><section class="widget widget-social_menu sep-after"><nav aria-label="Social Menu"><ul><li><a href=https://github.com/weihanglo target=_blank rel=noopener><span class=screen-reader-text>Open Github account in new tab</span><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77a5.44 5.44.0 00-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></li><li><a href=https://facebook.com/weihanglo target=_blank rel=noopener><span class=screen-reader-text>Open Facebook account in new tab</span><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M18 2h-3a5 5 0 00-5 5v3H7v4h3v8h4v-8h3l1-4h-4V7a1 1 0 011-1h3z"/></svg></a></li><li><a href=https://twitter.com/weihanglo target=_blank rel=noopener><span class=screen-reader-text>Open Twitter account in new tab</span><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><title>Twitter icon</title><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a></li><li><a href=https://linkedin.com/in/weihanglo target=_blank rel=noopener><span class=screen-reader-text>Open Linkedin account in new tab</span><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg></a></li><li><a href=https://t.me/weihanglo target=_blank rel=noopener><span class=screen-reader-text>Open Telegram account in new tab</span><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><title>Telegram icon</title><path d="M23.91 3.79 20.3 20.84c-.25 1.21-.98 1.5-2 .94l-5.5-4.07-2.66 2.57c-.3.3-.55.56-1.1.56-.72.0-.6-.27-.84-.95L6.3 13.7l-5.45-1.7c-1.18-.35-1.19-1.16.26-1.75l21.26-8.2c.97-.43 1.9.24 1.53 1.73z"/></svg></a></li></ul></nav></section><div class=copyright><p>&copy; 2017-2021 Weihang Lo</p></div></div></footer></div></div><script>window.__assets_js_src="/assets/js/"</script><script src=/assets/js/main.c3bcf2df.js></script><script src=/js/custom.js></script></body></html>